#### PPT中代码

train中 mask=None，暂且不看mask

pos_embedding_type="learnable" ???

PPT事先提取多张特征图

----

在yaml中定义了图片的大小

```
  IMAGE_SIZE:
  - 192
  - 256
```

不知道怎么转的，反正图片在 `lib/dataset/JointsDataset.py` 中都变成了192x256

```
img's size =  torch.Size([16, 3, 256, 192])
the shape of x =  torch.Size([16, 256, 64, 48])
```

这玩意之后怎么还原啊？😨 不知道换了方法会不会因为这个关节位置有影响、、、

----

##### PPT图片在输入transformer前的处理：

- 经过两层卷积和一个layer? 维度[n, 3, 256, 192]->[n, 256, 64, 48]
- rearrange 维度[n, 256, 64, 48]->[n, 256, 3072]
- embedding ->[n, 256, 192]
- 加上pos_embedding后加上关节token ->[n,273, 192]
- x输入transformer

##### CF-ViT图片在输入transformer前的处理：

- 在 deit/engine_deit.py 中将原图片上采样，长宽为原先的1/2，与原图片形成列表输入，输入格式为[(n, 3, 112, 112), (n, 3, 224, 224)]
- 在 deit/models_deit.py 中将上采样数据embedding ->(n, 49, 768)
- 加入分类token然后加上pos_embedding ->(n, 50, 768)
- x输入transformer

| transformer的过程 | PPT                                                          | CV-ViT                                                       |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| attention         | 层正则，多头得到qkv，qk点乘缩放得到attn，attn和v乘后rearrange、然后linear+dropout得到输出x；tok_attn是17个关节对其他x的注意力 | 层正则，多头得到qkv，qk点乘缩放得到attn，dropout(attn)，attn和v乘后rearrange、然后linear + dropout得到输出x；attn不变；x又叠了几层dropPath和mlp |
|                   |                                                              |                                                              |
|                   |                                                              |                                                              |

