#### CF-ViT    #这人写的代码太乱

/CF-ViT-main/deit/engine_deit.py

进行一轮训练

CF-ViT-main/deit/models_deit.py 继承自 code/deit-main/models_v2.py

模型

```
class Attention(nn.Module):
将图片分块且embedding，输入维度为(n,3,224,224)，输出维度为(n,768,196)
```

----

timm : Py**T**orch**Im**age**M**odels

在自定义的model前加上@register_model，创建的时候model = create_model(名字)

----

在构造好了一个模型后，可能要加载一些训练好的模型参数  model.load_state_dict()

----

lvvit中的MultiResoPatchEmbed在转换前多了3层卷积

----

forward:

coarse：先分块和embedding，加pos embedding，drop(?)，进行多个block attention norm

fine：设置好数据集

reuse：                  ![CF-ViT0.png](https://github.com/kaki-blue/MYIMAGES/blob/main/img/CF-ViT0.png?raw=true)

粗粒度的输出经过mlp参数的学习和维度转换后上采样成细粒度块大小的参数得到特征图

**先把所有的细粒度块和FR加在一起，然后进行信息筛选**

----

基于DeiT的修改：

- 加了一个 img_size_list=[112, 224]，手动分成粗粒度和细粒度

- reuse_block
- 输入的数据xx是列表有两组数据，原数据上采样：把224x224的图片上采样成112x112，操作相同

----

#### 在PPT中修改代码

PPT中的attention有mask，CF中没有；PPT中输出attn可选

CF是先将粗粒度过一遍所有的block，reuse后再重新过一遍block；PPT是在block中间的几层插入修剪

即将需要解决的问题：

- COCO中图片大小不固定，首先解决一下CF中patch_list变成根据输入设定
- 把修剪替换成coarseToFine还是二者融合
----
